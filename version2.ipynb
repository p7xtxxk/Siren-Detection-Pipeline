{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7eeebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\python\\lib\\site-packages (1.7.2)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.14.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl.metadata (52 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\python\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\python\\lib\\site-packages (from tensorflow) (6.32.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in c:\\python\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\python\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\python\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\python\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.13.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python\\lib\\site-packages (from tensorflow) (2.3.3)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.10-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\python\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (11.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.63.1-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python\\lib\\site-packages (from librosa) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\python\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\prate\\appdata\\roaming\\python\\python313\\site-packages (from librosa) (5.2.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.2-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting standard-aifc (from librosa)\n",
      "  Downloading standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)\n",
      "Collecting standard-sunau (from librosa)\n",
      "  Downloading standard_sunau-3.13.0-py3-none-any.whl.metadata (914 bytes)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting sklearn-compat<0.2,>=0.1.5 (from imbalanced-learn)\n",
      "  Downloading sklearn_compat-0.1.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl.metadata (116 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: rich in c:\\python\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.18.0-cp313-cp313-win_amd64.whl.metadata (35 kB)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.46.0-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\python\\lib\\site-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\python\\lib\\site-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
      "Requirement already satisfied: pycparser in c:\\python\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\python\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Collecting standard-chunk (from standard-aifc->librosa)\n",
      "  Downloading standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)\n",
      "Collecting audioop-lts (from standard-aifc->librosa)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Downloading tensorflow-2.20.0-cp313-cp313-win_amd64.whl (332.0 MB)\n",
      "   ---------------------------------------- 0.0/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/332.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/332.0 MB 1.4 MB/s eta 0:03:51\n",
      "   ---------------------------------------- 0.8/332.0 MB 1.3 MB/s eta 0:04:13\n",
      "   ---------------------------------------- 1.3/332.0 MB 1.7 MB/s eta 0:03:16\n",
      "   ---------------------------------------- 1.6/332.0 MB 1.6 MB/s eta 0:03:24\n",
      "   ---------------------------------------- 1.6/332.0 MB 1.6 MB/s eta 0:03:24\n",
      "   ---------------------------------------- 1.6/332.0 MB 1.6 MB/s eta 0:03:24\n",
      "   ---------------------------------------- 1.8/332.0 MB 1.1 MB/s eta 0:04:48\n",
      "   ---------------------------------------- 2.4/332.0 MB 1.3 MB/s eta 0:04:08\n",
      "   ---------------------------------------- 2.9/332.0 MB 1.4 MB/s eta 0:03:50\n",
      "   ---------------------------------------- 3.4/332.0 MB 1.6 MB/s eta 0:03:31\n",
      "   ---------------------------------------- 3.4/332.0 MB 1.6 MB/s eta 0:03:31\n",
      "   ---------------------------------------- 3.7/332.0 MB 1.4 MB/s eta 0:03:56\n",
      "    --------------------------------------- 4.5/332.0 MB 1.5 MB/s eta 0:03:32\n",
      "    --------------------------------------- 5.0/332.0 MB 1.6 MB/s eta 0:03:24\n",
      "    --------------------------------------- 5.8/332.0 MB 1.7 MB/s eta 0:03:08\n",
      "    --------------------------------------- 6.3/332.0 MB 1.8 MB/s eta 0:03:00\n",
      "    --------------------------------------- 6.6/332.0 MB 1.8 MB/s eta 0:03:02\n",
      "    --------------------------------------- 7.3/332.0 MB 1.9 MB/s eta 0:02:52\n",
      "    --------------------------------------- 8.1/332.0 MB 2.0 MB/s eta 0:02:43\n",
      "   - -------------------------------------- 8.7/332.0 MB 2.0 MB/s eta 0:02:38\n",
      "   - -------------------------------------- 9.2/332.0 MB 2.1 MB/s eta 0:02:36\n",
      "   - -------------------------------------- 9.7/332.0 MB 2.1 MB/s eta 0:02:34\n",
      "   - -------------------------------------- 10.0/332.0 MB 2.1 MB/s eta 0:02:34\n",
      "   - -------------------------------------- 10.5/332.0 MB 2.1 MB/s eta 0:02:36\n",
      "   - -------------------------------------- 11.3/332.0 MB 2.1 MB/s eta 0:02:32\n",
      "   - -------------------------------------- 12.1/332.0 MB 2.2 MB/s eta 0:02:27\n",
      "   - -------------------------------------- 12.6/332.0 MB 2.2 MB/s eta 0:02:27\n",
      "   - -------------------------------------- 13.1/332.0 MB 2.2 MB/s eta 0:02:25\n",
      "   - -------------------------------------- 13.6/332.0 MB 2.2 MB/s eta 0:02:25\n",
      "   - -------------------------------------- 13.9/332.0 MB 2.2 MB/s eta 0:02:26\n",
      "   - -------------------------------------- 14.7/332.0 MB 2.2 MB/s eta 0:02:23\n",
      "   - -------------------------------------- 15.2/332.0 MB 2.2 MB/s eta 0:02:22\n",
      "   - -------------------------------------- 15.7/332.0 MB 2.3 MB/s eta 0:02:21\n",
      "   - -------------------------------------- 16.3/332.0 MB 2.3 MB/s eta 0:02:20\n",
      "   -- ------------------------------------- 16.8/332.0 MB 2.3 MB/s eta 0:02:20\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.0/332.0 MB 2.3 MB/s eta 0:02:19\n",
      "   -- ------------------------------------- 17.3/332.0 MB 1.9 MB/s eta 0:02:46\n",
      "   -- ------------------------------------- 17.3/332.0 MB 1.9 MB/s eta 0:02:46\n",
      "   -- ------------------------------------- 17.8/332.0 MB 1.9 MB/s eta 0:02:49\n",
      "   -- ------------------------------------- 18.6/332.0 MB 1.9 MB/s eta 0:02:45\n",
      "   -- ------------------------------------- 19.4/332.0 MB 2.0 MB/s eta 0:02:41\n",
      "   -- ------------------------------------- 20.4/332.0 MB 2.0 MB/s eta 0:02:36\n",
      "   -- ------------------------------------- 21.0/332.0 MB 2.0 MB/s eta 0:02:34\n",
      "   -- ------------------------------------- 21.5/332.0 MB 2.0 MB/s eta 0:02:33\n",
      "   -- ------------------------------------- 22.3/332.0 MB 2.0 MB/s eta 0:02:32\n",
      "   -- ------------------------------------- 22.8/332.0 MB 2.1 MB/s eta 0:02:30\n",
      "   -- ------------------------------------- 23.9/332.0 MB 2.1 MB/s eta 0:02:26\n",
      "   --- ------------------------------------ 24.9/332.0 MB 2.2 MB/s eta 0:02:22\n",
      "   --- ------------------------------------ 26.0/332.0 MB 2.2 MB/s eta 0:02:19\n",
      "   --- ------------------------------------ 26.7/332.0 MB 2.2 MB/s eta 0:02:16\n",
      "   --- ------------------------------------ 27.8/332.0 MB 2.3 MB/s eta 0:02:13\n",
      "   --- ------------------------------------ 28.6/332.0 MB 2.3 MB/s eta 0:02:12\n",
      "   --- ------------------------------------ 29.6/332.0 MB 2.4 MB/s eta 0:02:08\n",
      "   --- ------------------------------------ 30.7/332.0 MB 2.4 MB/s eta 0:02:06\n",
      "   --- ------------------------------------ 31.7/332.0 MB 2.5 MB/s eta 0:02:03\n",
      "   --- ------------------------------------ 33.0/332.0 MB 2.5 MB/s eta 0:02:00\n",
      "   ---- ----------------------------------- 34.3/332.0 MB 2.6 MB/s eta 0:01:57\n",
      "   ---- ----------------------------------- 35.4/332.0 MB 2.6 MB/s eta 0:01:54\n",
      "   ---- ----------------------------------- 36.7/332.0 MB 2.7 MB/s eta 0:01:52\n",
      "   ---- ----------------------------------- 38.0/332.0 MB 2.7 MB/s eta 0:01:49\n",
      "   ---- ----------------------------------- 38.8/332.0 MB 2.7 MB/s eta 0:01:48\n",
      "   ---- ----------------------------------- 39.8/332.0 MB 2.8 MB/s eta 0:01:46\n",
      "   ---- ----------------------------------- 41.4/332.0 MB 2.8 MB/s eta 0:01:43\n",
      "   ----- ---------------------------------- 42.5/332.0 MB 2.9 MB/s eta 0:01:42\n",
      "   ----- ---------------------------------- 43.8/332.0 MB 2.9 MB/s eta 0:01:40\n",
      "   ----- ---------------------------------- 44.8/332.0 MB 2.9 MB/s eta 0:01:39\n",
      "   ----- ---------------------------------- 45.6/332.0 MB 3.0 MB/s eta 0:01:38\n",
      "   ----- ---------------------------------- 46.9/332.0 MB 3.0 MB/s eta 0:01:36\n",
      "   ----- ---------------------------------- 47.7/332.0 MB 3.0 MB/s eta 0:01:35\n",
      "   ----- ---------------------------------- 49.0/332.0 MB 3.0 MB/s eta 0:01:34\n",
      "   ------ --------------------------------- 50.3/332.0 MB 3.1 MB/s eta 0:01:32\n",
      "   ------ --------------------------------- 51.6/332.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ------ --------------------------------- 52.4/332.0 MB 3.1 MB/s eta 0:01:30\n",
      "   ------ --------------------------------- 53.2/332.0 MB 3.1 MB/s eta 0:01:29\n",
      "   ------ --------------------------------- 54.0/332.0 MB 3.1 MB/s eta 0:01:29\n",
      "   ------ --------------------------------- 54.8/332.0 MB 3.1 MB/s eta 0:01:29\n",
      "   ------ --------------------------------- 55.6/332.0 MB 3.2 MB/s eta 0:01:28\n",
      "   ------ --------------------------------- 56.1/332.0 MB 3.2 MB/s eta 0:01:27\n",
      "   ------ --------------------------------- 56.4/332.0 MB 3.1 MB/s eta 0:01:28\n",
      "   ------ --------------------------------- 57.7/332.0 MB 3.2 MB/s eta 0:01:27\n",
      "   ------- -------------------------------- 58.7/332.0 MB 3.2 MB/s eta 0:01:26\n",
      "   ------- -------------------------------- 60.0/332.0 MB 3.2 MB/s eta 0:01:25\n",
      "   ------- -------------------------------- 61.1/332.0 MB 3.2 MB/s eta 0:01:24\n",
      "   ------- -------------------------------- 62.1/332.0 MB 3.3 MB/s eta 0:01:23\n",
      "   ------- -------------------------------- 62.9/332.0 MB 3.3 MB/s eta 0:01:23\n",
      "   ------- -------------------------------- 64.0/332.0 MB 3.3 MB/s eta 0:01:22\n",
      "   ------- -------------------------------- 65.3/332.0 MB 3.3 MB/s eta 0:01:21\n",
      "   -------- ------------------------------- 66.8/332.0 MB 3.3 MB/s eta 0:01:20\n",
      "   -------- ------------------------------- 68.2/332.0 MB 3.4 MB/s eta 0:01:19\n",
      "   -------- ------------------------------- 69.7/332.0 MB 3.4 MB/s eta 0:01:17\n",
      "   -------- ------------------------------- 70.8/332.0 MB 3.4 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 71.8/332.0 MB 3.4 MB/s eta 0:01:16\n",
      "   -------- ------------------------------- 73.4/332.0 MB 3.5 MB/s eta 0:01:15\n",
      "   -------- ------------------------------- 74.4/332.0 MB 3.5 MB/s eta 0:01:14\n",
      "   --------- ------------------------------ 75.8/332.0 MB 3.5 MB/s eta 0:01:13\n",
      "   --------- ------------------------------ 77.3/332.0 MB 3.6 MB/s eta 0:01:12\n",
      "   --------- ------------------------------ 78.4/332.0 MB 3.6 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 79.2/332.0 MB 3.6 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 80.2/332.0 MB 3.6 MB/s eta 0:01:11\n",
      "   --------- ------------------------------ 81.5/332.0 MB 3.6 MB/s eta 0:01:10\n",
      "   --------- ------------------------------ 82.6/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 83.4/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 84.1/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 84.7/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 84.7/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 84.7/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 84.7/332.0 MB 3.6 MB/s eta 0:01:09\n",
      "   ---------- ----------------------------- 85.2/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 85.2/332.0 MB 3.5 MB/s eta 0:01:10\n",
      "   ---------- ----------------------------- 86.0/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 86.2/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 86.5/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 86.5/332.0 MB 3.5 MB/s eta 0:01:11\n",
      "   ---------- ----------------------------- 87.3/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 87.8/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 88.1/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 88.9/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 89.4/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 90.2/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 90.4/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 91.0/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 91.2/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ---------- ----------------------------- 91.2/332.0 MB 3.4 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 91.8/332.0 MB 3.3 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 92.3/332.0 MB 3.3 MB/s eta 0:01:13\n",
      "   ----------- ---------------------------- 92.8/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 93.6/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 94.4/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 94.9/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 95.7/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 96.2/332.0 MB 3.3 MB/s eta 0:01:12\n",
      "   ----------- ---------------------------- 96.7/332.0 MB 3.3 MB/s eta 0:01:11\n",
      "   ----------- ---------------------------- 97.5/332.0 MB 3.3 MB/s eta 0:01:11\n",
      "   ----------- ---------------------------- 98.0/332.0 MB 3.3 MB/s eta 0:01:11\n",
      "   ----------- ---------------------------- 98.8/332.0 MB 3.3 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 99.6/332.0 MB 3.3 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 99.9/332.0 MB 3.3 MB/s eta 0:01:11\n",
      "   ------------ --------------------------- 100.7/332.0 MB 3.3 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 101.2/332.0 MB 3.3 MB/s eta 0:01:10\n",
      "   ------------ --------------------------- 101.7/332.0 MB 3.3 MB/s eta 0:01:09\n",
      "   ------------ --------------------------- 102.5/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 103.3/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 103.5/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 103.5/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 104.1/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 104.6/332.0 MB 3.4 MB/s eta 0:01:07\n",
      "   ------------ --------------------------- 105.1/332.0 MB 3.4 MB/s eta 0:01:07\n",
      "   ------------ --------------------------- 105.6/332.0 MB 3.4 MB/s eta 0:01:07\n",
      "   ------------ --------------------------- 105.9/332.0 MB 3.4 MB/s eta 0:01:07\n",
      "   ------------ --------------------------- 106.2/332.0 MB 3.4 MB/s eta 0:01:07\n",
      "   ------------ --------------------------- 106.4/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 106.7/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 107.2/332.0 MB 3.4 MB/s eta 0:01:08\n",
      "   ------------ --------------------------- 107.7/332.0 MB 3.3 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 108.5/332.0 MB 3.3 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 108.8/332.0 MB 3.3 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 109.6/332.0 MB 3.3 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 110.1/332.0 MB 3.4 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 110.6/332.0 MB 3.4 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 111.1/332.0 MB 3.3 MB/s eta 0:01:07\n",
      "   ------------- -------------------------- 111.7/332.0 MB 3.3 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 112.2/332.0 MB 3.3 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 113.0/332.0 MB 3.3 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 113.2/332.0 MB 3.3 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 113.8/332.0 MB 3.3 MB/s eta 0:01:06\n",
      "   ------------- -------------------------- 114.6/332.0 MB 3.3 MB/s eta 0:01:05\n",
      "   ------------- -------------------------- 115.1/332.0 MB 3.3 MB/s eta 0:01:05\n",
      "   ------------- -------------------------- 115.9/332.0 MB 3.4 MB/s eta 0:01:05\n",
      "   -------------- ------------------------- 116.4/332.0 MB 3.4 MB/s eta 0:01:05\n",
      "   -------------- ------------------------- 117.2/332.0 MB 3.4 MB/s eta 0:01:04\n",
      "   -------------- ------------------------- 118.0/332.0 MB 3.5 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 118.5/332.0 MB 3.5 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 119.3/332.0 MB 3.5 MB/s eta 0:01:01\n",
      "   -------------- ------------------------- 120.1/332.0 MB 3.5 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 120.8/332.0 MB 3.5 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 121.6/332.0 MB 3.5 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 122.2/332.0 MB 3.5 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 122.7/332.0 MB 3.5 MB/s eta 0:01:00\n",
      "   -------------- ------------------------- 123.2/332.0 MB 3.6 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 123.7/332.0 MB 3.5 MB/s eta 0:00:59\n",
      "   -------------- ------------------------- 124.3/332.0 MB 3.5 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 125.0/332.0 MB 3.5 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 125.6/332.0 MB 3.5 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 126.1/332.0 MB 3.5 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 126.9/332.0 MB 3.5 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 127.7/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 128.2/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 129.0/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 129.5/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 130.0/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 130.5/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 130.8/332.0 MB 3.5 MB/s eta 0:00:58\n",
      "   --------------- ------------------------ 131.1/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 131.6/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   --------------- ------------------------ 132.4/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 133.4/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 134.2/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 135.0/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 135.8/332.0 MB 3.4 MB/s eta 0:00:59\n",
      "   ---------------- ----------------------- 136.8/332.0 MB 3.4 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 137.9/332.0 MB 3.4 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 139.2/332.0 MB 3.4 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 139.7/332.0 MB 3.4 MB/s eta 0:00:58\n",
      "   ---------------- ----------------------- 140.8/332.0 MB 3.3 MB/s eta 0:00:58\n",
      "   ----------------- ---------------------- 141.8/332.0 MB 3.3 MB/s eta 0:00:58\n",
      "   ----------------- ---------------------- 142.9/332.0 MB 3.3 MB/s eta 0:00:57\n",
      "   ----------------- ---------------------- 143.7/332.0 MB 3.3 MB/s eta 0:00:57\n",
      "   ----------------- ---------------------- 145.0/332.0 MB 3.3 MB/s eta 0:00:57\n",
      "   ----------------- ---------------------- 146.5/332.0 MB 3.3 MB/s eta 0:00:56\n",
      "   ----------------- ---------------------- 147.8/332.0 MB 3.4 MB/s eta 0:00:55\n",
      "   ----------------- ---------------------- 148.9/332.0 MB 3.4 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 149.9/332.0 MB 3.4 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 151.0/332.0 MB 3.3 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 151.8/332.0 MB 3.3 MB/s eta 0:00:55\n",
      "   ------------------ --------------------- 152.6/332.0 MB 3.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 153.4/332.0 MB 3.3 MB/s eta 0:00:54\n",
      "   ------------------ --------------------- 154.7/332.0 MB 3.3 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 156.0/332.0 MB 3.4 MB/s eta 0:00:53\n",
      "   ------------------ --------------------- 157.0/332.0 MB 3.4 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 157.8/332.0 MB 3.4 MB/s eta 0:00:52\n",
      "   ------------------- -------------------- 159.1/332.0 MB 3.4 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 159.6/332.0 MB 3.4 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 161.2/332.0 MB 3.4 MB/s eta 0:00:51\n",
      "   ------------------- -------------------- 162.3/332.0 MB 3.4 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 163.3/332.0 MB 3.4 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 164.1/332.0 MB 3.4 MB/s eta 0:00:50\n",
      "   ------------------- -------------------- 165.2/332.0 MB 3.4 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 166.2/332.0 MB 3.4 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 166.2/332.0 MB 3.4 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 168.3/332.0 MB 3.4 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 169.3/332.0 MB 3.4 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 170.1/332.0 MB 3.4 MB/s eta 0:00:49\n",
      "   -------------------- ------------------- 171.4/332.0 MB 3.4 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 172.5/332.0 MB 3.4 MB/s eta 0:00:48\n",
      "   -------------------- ------------------- 173.5/332.0 MB 3.4 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 174.6/332.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 175.4/332.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 175.6/332.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 175.6/332.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 176.7/332.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 177.5/332.0 MB 3.2 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 177.7/332.0 MB 3.2 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 178.3/332.0 MB 3.2 MB/s eta 0:00:49\n",
      "   --------------------- ------------------ 179.6/332.0 MB 3.2 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 180.4/332.0 MB 3.2 MB/s eta 0:00:48\n",
      "   --------------------- ------------------ 181.7/332.0 MB 3.2 MB/s eta 0:00:47\n",
      "   ---------------------- ----------------- 182.7/332.0 MB 3.3 MB/s eta 0:00:45\n",
      "   ---------------------- ----------------- 183.8/332.0 MB 3.3 MB/s eta 0:00:45\n",
      "   ---------------------- ----------------- 184.3/332.0 MB 3.3 MB/s eta 0:00:45\n",
      "   ---------------------- ----------------- 185.1/332.0 MB 3.4 MB/s eta 0:00:44\n",
      "   ---------------------- ----------------- 186.1/332.0 MB 3.4 MB/s eta 0:00:44\n",
      "   ---------------------- ----------------- 186.9/332.0 MB 3.4 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 188.0/332.0 MB 3.4 MB/s eta 0:00:43\n",
      "   ---------------------- ----------------- 188.7/332.0 MB 3.4 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 189.8/332.0 MB 3.4 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 190.6/332.0 MB 3.4 MB/s eta 0:00:42\n",
      "   ---------------------- ----------------- 190.8/332.0 MB 3.4 MB/s eta 0:00:41\n",
      "   ----------------------- ---------------- 191.9/332.0 MB 3.5 MB/s eta 0:00:41\n",
      "   ----------------------- ---------------- 192.4/332.0 MB 3.5 MB/s eta 0:00:41\n",
      "   ----------------------- ---------------- 193.5/332.0 MB 3.5 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 194.2/332.0 MB 3.5 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 195.3/332.0 MB 3.5 MB/s eta 0:00:40\n",
      "   ----------------------- ---------------- 196.3/332.0 MB 3.5 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 197.1/332.0 MB 3.5 MB/s eta 0:00:39\n",
      "   ----------------------- ---------------- 198.2/332.0 MB 3.6 MB/s eta 0:00:38\n",
      "   ------------------------ --------------- 199.2/332.0 MB 3.6 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 200.0/332.0 MB 3.6 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 201.1/332.0 MB 3.6 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 201.6/332.0 MB 3.6 MB/s eta 0:00:37\n",
      "   ------------------------ --------------- 202.4/332.0 MB 3.6 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 203.7/332.0 MB 3.6 MB/s eta 0:00:36\n",
      "   ------------------------ --------------- 204.7/332.0 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 205.8/332.0 MB 3.7 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 206.0/332.0 MB 3.7 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 206.8/332.0 MB 3.7 MB/s eta 0:00:35\n",
      "   ------------------------ --------------- 207.4/332.0 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 207.9/332.0 MB 3.6 MB/s eta 0:00:35\n",
      "   ------------------------- -------------- 208.4/332.0 MB 3.6 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 209.5/332.0 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 210.5/332.0 MB 3.7 MB/s eta 0:00:34\n",
      "   ------------------------- -------------- 211.3/332.0 MB 3.7 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 212.3/332.0 MB 3.7 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 213.4/332.0 MB 3.7 MB/s eta 0:00:33\n",
      "   ------------------------- -------------- 213.9/332.0 MB 3.7 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 214.4/332.0 MB 3.7 MB/s eta 0:00:32\n",
      "   ------------------------- -------------- 215.0/332.0 MB 3.7 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 216.0/332.0 MB 3.7 MB/s eta 0:00:32\n",
      "   -------------------------- ------------- 217.3/332.0 MB 3.8 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 218.4/332.0 MB 3.8 MB/s eta 0:00:31\n",
      "   -------------------------- ------------- 219.7/332.0 MB 3.8 MB/s eta 0:00:30\n",
      "   -------------------------- ------------- 221.0/332.0 MB 3.8 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 222.3/332.0 MB 3.9 MB/s eta 0:00:29\n",
      "   -------------------------- ------------- 223.6/332.0 MB 3.9 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 224.4/332.0 MB 3.9 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 225.4/332.0 MB 3.9 MB/s eta 0:00:28\n",
      "   --------------------------- ------------ 226.2/332.0 MB 4.0 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 227.5/332.0 MB 4.0 MB/s eta 0:00:27\n",
      "   --------------------------- ------------ 228.9/332.0 MB 4.0 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 229.9/332.0 MB 4.0 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 230.4/332.0 MB 4.0 MB/s eta 0:00:26\n",
      "   --------------------------- ------------ 231.5/332.0 MB 4.0 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 232.8/332.0 MB 4.1 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 234.1/332.0 MB 4.1 MB/s eta 0:00:25\n",
      "   ---------------------------- ----------- 235.4/332.0 MB 4.1 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 235.9/332.0 MB 4.1 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 237.0/332.0 MB 4.1 MB/s eta 0:00:24\n",
      "   ---------------------------- ----------- 237.8/332.0 MB 4.1 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 238.8/332.0 MB 4.1 MB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 239.9/332.0 MB 4.2 MB/s eta 0:00:23\n",
      "   ----------------------------- ---------- 240.9/332.0 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 242.0/332.0 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 243.3/332.0 MB 4.2 MB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 244.3/332.0 MB 4.2 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 245.4/332.0 MB 4.2 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 246.7/332.0 MB 4.2 MB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 248.3/332.0 MB 4.3 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 249.3/332.0 MB 4.3 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 250.3/332.0 MB 4.3 MB/s eta 0:00:20\n",
      "   ------------------------------ --------- 251.4/332.0 MB 4.3 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 252.4/332.0 MB 4.3 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 253.5/332.0 MB 4.3 MB/s eta 0:00:19\n",
      "   ------------------------------ --------- 254.0/332.0 MB 4.3 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 255.1/332.0 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 256.1/332.0 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------ --------- 256.9/332.0 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------------------------- -------- 258.2/332.0 MB 4.4 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 259.3/332.0 MB 4.4 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 260.6/332.0 MB 4.4 MB/s eta 0:00:17\n",
      "   ------------------------------- -------- 261.6/332.0 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 262.4/332.0 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 262.9/332.0 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 263.7/332.0 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 264.5/332.0 MB 4.5 MB/s eta 0:00:16\n",
      "   ------------------------------- -------- 264.8/332.0 MB 4.5 MB/s eta 0:00:16\n",
      "   -------------------------------- ------- 265.8/332.0 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 266.9/332.0 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 267.6/332.0 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 268.4/332.0 MB 4.5 MB/s eta 0:00:15\n",
      "   -------------------------------- ------- 269.5/332.0 MB 4.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 270.5/332.0 MB 4.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 271.1/332.0 MB 4.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 272.1/332.0 MB 4.5 MB/s eta 0:00:14\n",
      "   -------------------------------- ------- 272.9/332.0 MB 4.5 MB/s eta 0:00:14\n",
      "   --------------------------------- ------ 273.9/332.0 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 275.0/332.0 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 275.8/332.0 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 277.1/332.0 MB 4.5 MB/s eta 0:00:13\n",
      "   --------------------------------- ------ 277.9/332.0 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 278.7/332.0 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 279.4/332.0 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 280.2/332.0 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 281.0/332.0 MB 4.5 MB/s eta 0:00:12\n",
      "   --------------------------------- ------ 282.1/332.0 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 282.9/332.0 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 283.9/332.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 285.0/332.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 285.7/332.0 MB 4.5 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 286.3/332.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 287.3/332.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 287.8/332.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 288.9/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 289.4/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 290.5/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 291.0/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.0/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.6/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.6/332.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 292.8/332.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 293.9/332.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 294.6/332.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 295.4/332.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 296.2/332.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 296.7/332.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 297.0/332.0 MB 4.3 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 297.3/332.0 MB 4.2 MB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 298.1/332.0 MB 4.2 MB/s eta 0:00:09\n",
      "   ------------------------------------ --- 298.8/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 299.6/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 300.4/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 300.7/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 301.5/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 301.7/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 302.5/332.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ------------------------------------ --- 303.0/332.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 303.8/332.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 304.3/332.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 305.1/332.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 305.9/332.0 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------------------------------ --- 306.4/332.0 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 307.2/332.0 MB 4.1 MB/s eta 0:00:07\n",
      "   ------------------------------------- -- 308.3/332.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 309.3/332.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 310.1/332.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 310.9/332.0 MB 4.1 MB/s eta 0:00:06\n",
      "   ------------------------------------- -- 311.7/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 312.2/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 312.7/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 313.8/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 314.3/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 315.1/332.0 MB 4.1 MB/s eta 0:00:05\n",
      "   -------------------------------------- - 316.1/332.0 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 316.4/332.0 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 316.7/332.0 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 316.9/332.0 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 317.7/332.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 318.0/332.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 318.5/332.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 319.0/332.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 319.8/332.0 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------------------- - 320.3/332.0 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 320.9/332.0 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 321.4/332.0 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 322.2/332.0 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 322.7/332.0 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 323.0/332.0 MB 3.9 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 323.2/332.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  323.7/332.0 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------------------  324.3/332.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  324.8/332.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.1/332.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  325.6/332.0 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.1/332.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  326.4/332.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.2/332.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  327.9/332.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------------  328.7/332.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.3/332.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.5/332.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  329.8/332.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.0/332.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.3/332.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  330.8/332.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.4/332.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  331.9/332.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 332.0/332.0 MB 3.5 MB/s  0:01:34\n",
      "Downloading grpcio-1.76.0-cp313-cp313-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.5/4.7 MB 2.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.0/4.7 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.6/4.7 MB 2.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.4/4.7 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.9/4.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.2/4.7 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 2.9 MB/s  0:00:01\n",
      "Downloading ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.5/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.0/5.5 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.8/5.5 MB 3.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.6/5.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.4/5.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 4.7/5.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 3.2 MB/s  0:00:01\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Downloading imbalanced_learn-0.14.1-py3-none-any.whl (235 kB)\n",
      "Downloading sklearn_compat-0.1.5-py3-none-any.whl (20 kB)\n",
      "Downloading matplotlib-3.10.8-cp313-cp313-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 2.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.6/8.1 MB 2.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.1/8.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.6/8.1 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.4/8.1 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.9/8.1 MB 2.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.2/8.1 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.0/8.1 MB 2.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.1 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.1/8.1 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 3.0 MB/s  0:00:02\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Downloading contourpy-1.3.3-cp313-cp313-win_amd64.whl (226 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Downloading fonttools-4.61.1-cp313-cp313-win_amd64.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 2.8 MB/s  0:00:00\n",
      "Downloading gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.15.1-cp313-cp313-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.9 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.8/2.9 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/2.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 2.9 MB/s  0:00:00\n",
      "Downloading keras-3.13.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 3.6 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp313-cp313-win_amd64.whl (73 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/26.4 MB 3.5 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.3/26.4 MB 3.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/26.4 MB 3.6 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 3.5 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 3.4 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.2/26.4 MB 3.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 4.7/26.4 MB 3.3 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.8/26.4 MB 3.4 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.6/26.4 MB 3.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.1/26.4 MB 3.5 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 9.2/26.4 MB 3.7 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 10.2/26.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 11.0/26.4 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 12.1/26.4 MB 3.8 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 13.1/26.4 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.9/26.4 MB 3.9 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.7/26.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.5/26.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.3/26.4 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 17.0/26.4 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 17.8/26.4 MB 3.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 19.7/26.4 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.2/26.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.4/26.4 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 21.5/26.4 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.3/26.4 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 23.1/26.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.1/26.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.9/26.4 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.4/26.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 3.7 MB/s  0:00:07\n",
      "Downloading markdown-3.10-py3-none-any.whl (107 kB)\n",
      "Downloading msgpack-1.1.2-cp313-cp313-win_amd64.whl (72 kB)\n",
      "Downloading numba-0.63.1-cp313-cp313-win_amd64.whl (2.8 MB)\n",
      "   ---------------------------------------- 0.0/2.8 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.3/2.8 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.8 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.8/2.8 MB 3.3 MB/s  0:00:00\n",
      "Downloading llvmlite-0.46.0-cp313-cp313-win_amd64.whl (38.1 MB)\n",
      "   ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/38.1 MB 4.9 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.8/38.1 MB 4.9 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.6/38.1 MB 4.6 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 3.4/38.1 MB 4.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 4.2/38.1 MB 4.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 5.0/38.1 MB 4.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 6.0/38.1 MB 4.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.1/38.1 MB 4.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 7.9/38.1 MB 4.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.7/38.1 MB 4.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 8.9/38.1 MB 4.1 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 9.2/38.1 MB 3.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 10.5/38.1 MB 3.9 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 11.5/38.1 MB 3.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 12.3/38.1 MB 3.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 12.8/38.1 MB 3.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 13.6/38.1 MB 3.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 14.2/38.1 MB 3.7 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 15.2/38.1 MB 3.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 16.3/38.1 MB 3.8 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 17.6/38.1 MB 3.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 18.9/38.1 MB 4.0 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 19.9/38.1 MB 4.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 21.2/38.1 MB 4.2 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 22.0/38.1 MB 4.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.1/38.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 23.6/38.1 MB 4.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 24.4/38.1 MB 4.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 24.9/38.1 MB 4.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 25.7/38.1 MB 4.0 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 26.7/38.1 MB 4.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 27.5/38.1 MB 4.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 28.0/38.1 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 28.8/38.1 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 29.9/38.1 MB 4.0 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 30.7/38.1 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 31.5/38.1 MB 4.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 32.2/38.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 33.0/38.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 33.8/38.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 34.6/38.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 35.4/38.1 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.4/38.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.2/38.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.0/38.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.1/38.1 MB 4.0 MB/s  0:00:09\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Downloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.3 MB/s  0:00:00\n",
      "Downloading soxr-1.0.0-cp312-abi3-win_amd64.whl (172 kB)\n",
      "Downloading termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.4-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.18.0-cp313-cp313-win_amd64.whl (314 kB)\n",
      "Downloading standard_aifc-3.13.0-py3-none-any.whl (10 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)\n",
      "Downloading standard_sunau-3.13.0-py3-none-any.whl (7.4 kB)\n",
      "Installing collected packages: standard-chunk, namex, libclang, flatbuffers, wheel, werkzeug, termcolor, tensorboard-data-server, soxr, pyparsing, optree, opt_einsum, msgpack, ml_dtypes, markdown, llvmlite, lazy_loader, kiwisolver, h5py, grpcio, google_pasta, gast, fonttools, cycler, contourpy, audioop-lts, absl-py, tensorboard, standard-sunau, standard-aifc, soundfile, pooch, numba, matplotlib, astunparse, sklearn-compat, keras, audioread, tensorflow, librosa, imbalanced-learn\n",
      "\n",
      "   - --------------------------------------  2/41 [libclang]\n",
      "   - --------------------------------------  2/41 [libclang]\n",
      "   - --------------------------------------  2/41 [libclang]\n",
      "   - --------------------------------------  2/41 [libclang]\n",
      "   -- -------------------------------------  3/41 [flatbuffers]\n",
      "   --- ------------------------------------  4/41 [wheel]\n",
      "   --- ------------------------------------  4/41 [wheel]\n",
      "   --- ------------------------------------  4/41 [wheel]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ---- -----------------------------------  5/41 [werkzeug]\n",
      "   ------ ---------------------------------  7/41 [tensorboard-data-server]\n",
      "   -------- -------------------------------  9/41 [pyparsing]\n",
      "   -------- -------------------------------  9/41 [pyparsing]\n",
      "   --------- ------------------------------ 10/41 [optree]\n",
      "   --------- ------------------------------ 10/41 [optree]\n",
      "   --------- ------------------------------ 10/41 [optree]\n",
      "   ---------- ----------------------------- 11/41 [opt_einsum]\n",
      "   ---------- ----------------------------- 11/41 [opt_einsum]\n",
      "   ---------- ----------------------------- 11/41 [opt_einsum]\n",
      "   ----------- ---------------------------- 12/41 [msgpack]\n",
      "   ------------- -------------------------- 14/41 [markdown]\n",
      "   ------------- -------------------------- 14/41 [markdown]\n",
      "   ------------- -------------------------- 14/41 [markdown]\n",
      "   ------------- -------------------------- 14/41 [markdown]\n",
      "   ------------- -------------------------- 14/41 [markdown]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   -------------- ------------------------- 15/41 [llvmlite]\n",
      "   --------------- ------------------------ 16/41 [lazy_loader]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ----------------- ---------------------- 18/41 [h5py]\n",
      "   ------------------ --------------------- 19/41 [grpcio]\n",
      "   ------------------ --------------------- 19/41 [grpcio]\n",
      "   ------------------ --------------------- 19/41 [grpcio]\n",
      "   ------------------ --------------------- 19/41 [grpcio]\n",
      "   ------------------ --------------------- 19/41 [grpcio]\n",
      "   ------------------ --------------------- 19/41 [grpcio]\n",
      "   ------------------- -------------------- 20/41 [google_pasta]\n",
      "   ------------------- -------------------- 20/41 [google_pasta]\n",
      "   -------------------- ------------------- 21/41 [gast]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   --------------------- ------------------ 22/41 [fonttools]\n",
      "   ----------------------- ---------------- 24/41 [contourpy]\n",
      "   ----------------------- ---------------- 24/41 [contourpy]\n",
      "   ------------------------- -------------- 26/41 [absl-py]\n",
      "   ------------------------- -------------- 26/41 [absl-py]\n",
      "   ------------------------- -------------- 26/41 [absl-py]\n",
      "   ------------------------- -------------- 26/41 [absl-py]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   -------------------------- ------------- 27/41 [tensorboard]\n",
      "   ----------------------------- ---------- 30/41 [soundfile]\n",
      "   ------------------------------ --------- 31/41 [pooch]\n",
      "   ------------------------------ --------- 31/41 [pooch]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   ------------------------------- -------- 32/41 [numba]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   -------------------------------- ------- 33/41 [matplotlib]\n",
      "   --------------------------------- ------ 34/41 [astunparse]\n",
      "   ---------------------------------- ----- 35/41 [sklearn-compat]\n",
      "   ---------------------------------- ----- 35/41 [sklearn-compat]\n",
      "   ---------------------------------- ----- 35/41 [sklearn-compat]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ----------------------------------- ---- 36/41 [keras]\n",
      "   ------------------------------------ --- 37/41 [audioread]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   ------------------------------------- -- 38/41 [tensorflow]\n",
      "   -------------------------------------- - 39/41 [librosa]\n",
      "   -------------------------------------- - 39/41 [librosa]\n",
      "   -------------------------------------- - 39/41 [librosa]\n",
      "   -------------------------------------- - 39/41 [librosa]\n",
      "   -------------------------------------- - 39/41 [librosa]\n",
      "   -------------------------------------- - 39/41 [librosa]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------  40/41 [imbalanced-learn]\n",
      "   ---------------------------------------- 41/41 [imbalanced-learn]\n",
      "\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 audioop-lts-0.2.2 audioread-3.1.0 contourpy-1.3.3 cycler-0.12.1 flatbuffers-25.12.19 fonttools-4.61.1 gast-0.7.0 google_pasta-0.2.0 grpcio-1.76.0 h5py-3.15.1 imbalanced-learn-0.14.1 keras-3.13.0 kiwisolver-1.4.9 lazy_loader-0.4 libclang-18.1.1 librosa-0.11.0 llvmlite-0.46.0 markdown-3.10 matplotlib-3.10.8 ml_dtypes-0.5.4 msgpack-1.1.2 namex-0.1.0 numba-0.63.1 opt_einsum-3.4.0 optree-0.18.0 pooch-1.8.2 pyparsing-3.3.1 sklearn-compat-0.1.5 soundfile-0.13.1 soxr-1.0.0 standard-aifc-3.13.0 standard-chunk-3.13.0 standard-sunau-3.13.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 werkzeug-3.1.4 wheel-0.45.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow librosa scikit-learn imbalanced-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c313249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siren folder exists: True\n",
      "Non-siren folder exists: True\n",
      "Siren files: 40\n",
      "Non-siren files: 1960\n"
     ]
    }
   ],
   "source": [
    "import os, numpy as np, librosa\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set base paths\n",
    "BASE_DIR = Path(\"C:/Users/prate/Downloads/College Academics/Minor Project/Minor Project\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "SIREN_DIR = DATA_DIR / \"siren\"\n",
    "NON_DIR = DATA_DIR / \"non_siren\"\n",
    "\n",
    "# Confirm folders exist and contain .wav files\n",
    "print(\"Siren folder exists:\", SIREN_DIR.exists())\n",
    "print(\"Non-siren folder exists:\", NON_DIR.exists())\n",
    "print(\"Siren files:\", len(list(SIREN_DIR.glob(\"*.wav\"))))\n",
    "print(\"Non-siren files:\", len(list(NON_DIR.glob(\"*.wav\"))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50a9111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC dataset shape: (10000, 64, 130, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "SR = 22050\n",
    "WIN_SEC = 1.5\n",
    "HOP_SEC = 0.75\n",
    "WIN = int(SR * WIN_SEC)\n",
    "HOP = int(SR * HOP_SEC)\n",
    "\n",
    "def extract_logmel(x, sr=SR, n_mels=64):\n",
    "    S = librosa.feature.melspectrogram(y=x, sr=sr, n_fft=1024, hop_length=256, n_mels=n_mels)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    return log_S.astype(np.float32)\n",
    "\n",
    "def file_to_logmel(path, label):\n",
    "    x, sr = librosa.load(path.as_posix(), sr=SR, mono=True)\n",
    "    if np.max(np.abs(x)) > 0: \n",
    "        x = x / np.max(np.abs(x))\n",
    "    feats, labels = [], []\n",
    "    if len(x) < WIN: \n",
    "        x = np.pad(x, (0, WIN - len(x)))\n",
    "    for start in range(0, max(len(x) - WIN + 1, 1), HOP):\n",
    "        seg = x[start:start+WIN]\n",
    "        logmel = extract_logmel(seg)\n",
    "        feats.append(logmel)\n",
    "        labels.append(label)\n",
    "    return np.stack(feats), np.array(labels)\n",
    "\n",
    "# Build dataset\n",
    "X_list, y_list = [], []\n",
    "\n",
    "for p in SIREN_DIR.glob(\"*.wav\"):\n",
    "    fx, fy = file_to_logmel(p, 1)\n",
    "    X_list.append(fx); y_list.append(fy)\n",
    "\n",
    "for p in NON_DIR.glob(\"*.wav\"):\n",
    "    fx, fy = file_to_logmel(p, 0)\n",
    "    X_list.append(fx); y_list.append(fy)\n",
    "\n",
    "X = np.concatenate(X_list, axis=0)\n",
    "y = np.concatenate(y_list, axis=0)\n",
    "X = X[..., np.newaxis]  # Add channel dimension\n",
    "\n",
    "print(\"ESC dataset shape:\", X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e389bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> \n",
       "\n",
       " batch_normalization_4            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> \n",
       "\n",
       " batch_normalization_5            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
       "\n",
       " batch_normalization_6            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " batch_normalization_7            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " global_average_pooling2d_1       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
       "\n",
       " dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m160\u001b[0m \n",
       "\n",
       " batch_normalization_4            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)                \u001b[38;5;34m64\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_11 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)              \u001b[38;5;34m4,640\u001b[0m \n",
       "\n",
       " batch_normalization_5            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
       "\n",
       " batch_normalization_6            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " batch_normalization_7            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " global_average_pooling2d_1       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dense_10 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m8,256\u001b[0m \n",
       "\n",
       " dropout_5 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_11 (\u001b[38;5;33mDense\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m65\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,433</span> (415.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,433\u001b[0m (415.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,953</span> (413.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,953\u001b[0m (413.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 140ms/step - accuracy: 0.9759 - loss: 0.0871 - val_accuracy: 0.9769 - val_loss: 0.1231\n",
      "Epoch 2/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 140ms/step - accuracy: 0.9828 - loss: 0.0526 - val_accuracy: 0.9787 - val_loss: 0.0772\n",
      "Epoch 3/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 140ms/step - accuracy: 0.9869 - loss: 0.0408 - val_accuracy: 0.9769 - val_loss: 0.1278\n",
      "Epoch 4/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 0.9891 - loss: 0.0333 - val_accuracy: 0.9825 - val_loss: 0.0676\n",
      "Epoch 5/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 140ms/step - accuracy: 0.9905 - loss: 0.0300 - val_accuracy: 0.9825 - val_loss: 0.0698\n",
      "Epoch 6/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 141ms/step - accuracy: 0.9909 - loss: 0.0256 - val_accuracy: 0.9875 - val_loss: 0.0365\n",
      "Epoch 7/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9959 - loss: 0.0165 - val_accuracy: 0.9862 - val_loss: 0.0587\n",
      "Epoch 8/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 0.9937 - loss: 0.0166 - val_accuracy: 0.9919 - val_loss: 0.0279\n",
      "Epoch 9/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 0.9964 - loss: 0.0135 - val_accuracy: 0.9856 - val_loss: 0.0451\n",
      "Epoch 10/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9959 - loss: 0.0128 - val_accuracy: 0.9850 - val_loss: 0.0700\n",
      "Epoch 11/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 139ms/step - accuracy: 0.9947 - loss: 0.0140 - val_accuracy: 0.9894 - val_loss: 0.0462\n",
      "Epoch 12/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9958 - loss: 0.0145 - val_accuracy: 0.8994 - val_loss: 0.1807\n",
      "Epoch 13/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 138ms/step - accuracy: 0.9958 - loss: 0.0105 - val_accuracy: 0.9769 - val_loss: 0.1408\n",
      "Epoch 14/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 140ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9931 - val_loss: 0.0220\n",
      "Epoch 15/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 141ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9862 - val_loss: 0.0381\n",
      "Epoch 16/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9966 - loss: 0.0092 - val_accuracy: 0.9050 - val_loss: 0.1964\n",
      "Epoch 17/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 142ms/step - accuracy: 0.9969 - loss: 0.0101 - val_accuracy: 0.9862 - val_loss: 0.0323\n",
      "Epoch 18/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 142ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.9900 - val_loss: 0.0531\n",
      "Epoch 19/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 144ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.9831 - val_loss: 0.1113\n",
      "Epoch 20/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 142ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9969 - val_loss: 0.0206\n",
      "Epoch 21/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9919 - val_loss: 0.0455\n",
      "Epoch 22/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 141ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.4956 - val_loss: 1.7916\n",
      "Epoch 23/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 139ms/step - accuracy: 0.9942 - loss: 0.0197 - val_accuracy: 0.8144 - val_loss: 0.4313\n",
      "Epoch 24/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9919 - val_loss: 0.0291\n",
      "Epoch 25/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9812 - val_loss: 0.1976\n",
      "Epoch 26/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9806 - val_loss: 0.2049\n",
      "Epoch 27/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.9967 - loss: 0.0086 - val_accuracy: 0.9875 - val_loss: 0.0411\n",
      "Epoch 28/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 135ms/step - accuracy: 0.9975 - loss: 0.0088 - val_accuracy: 0.9844 - val_loss: 0.0433\n",
      "Epoch 29/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9944 - val_loss: 0.0304\n",
      "Epoch 30/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9931 - val_loss: 0.0315\n",
      "Epoch 31/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 139ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9969 - val_loss: 0.0152\n",
      "Epoch 32/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9981 - val_loss: 0.0154\n",
      "Epoch 33/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 137ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9969 - val_loss: 0.0179\n",
      "Epoch 34/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - accuracy: 1.0000 - loss: 2.5061e-04 - val_accuracy: 0.9969 - val_loss: 0.0176\n",
      "Epoch 35/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 3.7836e-04 - val_accuracy: 0.9975 - val_loss: 0.0134\n",
      "Epoch 36/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 139ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9944 - val_loss: 0.0222\n",
      "Epoch 37/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 3.8760e-04 - val_accuracy: 0.9944 - val_loss: 0.0241\n",
      "Epoch 38/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 3.4076e-04 - val_accuracy: 0.9869 - val_loss: 0.0425\n",
      "Epoch 39/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 142ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9800 - val_loss: 0.2004\n",
      "Epoch 40/40\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 142ms/step - accuracy: 0.9952 - loss: 0.0114 - val_accuracy: 0.9812 - val_loss: 0.1064\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9835 - loss: 0.0983\n",
      "ESC Test accuracy: 0.9835000038146973\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Train/test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, stratify=y, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# # Define lightweight CNN\n",
    "# input_shape = X.shape[1:]\n",
    "\n",
    "# model_esc = models.Sequential([\n",
    "#     layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "#     layers.MaxPooling2D((2,2)),\n",
    "#     layers.Conv2D(32, (3,3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2,2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model_esc.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model_esc.summary()\n",
    "\n",
    "# # Train\n",
    "# history = model_esc.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Evaluate\n",
    "# test_loss, test_acc = model_esc.evaluate(X_test, y_test)\n",
    "# print(\"ESC Test accuracy:\", test_acc)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define optimized CNN (same style as UrbanSound model)\n",
    "input_shape = X.shape[1:]\n",
    "\n",
    "model_esc = models.Sequential([\n",
    "    layers.Conv2D(16, (3,3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_esc.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_esc.summary()\n",
    "\n",
    "# Train\n",
    "history = model_esc.fit(X_train, y_train, epochs=40, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model_esc.evaluate(X_test, y_test)\n",
    "print(\"ESC Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0744cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
      "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
      "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
      "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
      "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
      "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
      "\n",
      "              class  \n",
      "0          dog_bark  \n",
      "1  children_playing  \n",
      "2  children_playing  \n",
      "3  children_playing  \n",
      "4  children_playing  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "US8K_DIR = BASE_DIR / \"datasets\" / \"UrbanSound8k\" / \"UrbanSound8K\"\n",
    "US8K_AUDIO = US8K_DIR / \"audio\"\n",
    "US8K_META = US8K_DIR / \"metadata\" / \"UrbanSound8K.csv\"\n",
    "\n",
    "# Load metadata\n",
    "meta = pd.read_csv(US8K_META)\n",
    "print(meta.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8a22b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "dog_bark            1000\n",
      "children_playing    1000\n",
      "air_conditioner     1000\n",
      "street_music        1000\n",
      "jackhammer          1000\n",
      "engine_idling       1000\n",
      "drilling            1000\n",
      "siren                929\n",
      "car_horn             429\n",
      "gun_shot             374\n",
      "Name: count, dtype: int64\n",
      "Total siren clips: 929\n"
     ]
    }
   ],
   "source": [
    "# Siren = label 1, everything else = label 0\n",
    "meta['label'] = meta['class'].apply(lambda c: 1 if c == 'siren' else 0)\n",
    "\n",
    "print(meta['class'].value_counts())\n",
    "print(\"Total siren clips:\", (meta['label'] == 1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb9a5049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UrbanSound8K dataset shape: (31217, 64, 130, 1) (31217,)\n"
     ]
    }
   ],
   "source": [
    "X_list, y_list = [], []\n",
    "\n",
    "for i, row in meta.iterrows():\n",
    "    file_name = row[\"slice_file_name\"]\n",
    "    fold = row[\"fold\"]\n",
    "    label = row[\"label\"]   # 1 for siren, 0 otherwise\n",
    "    \n",
    "    file_path = US8K_AUDIO / f\"fold{fold}\" / file_name\n",
    "    if file_path.exists():\n",
    "        fx, fy = file_to_logmel(file_path, label)\n",
    "        X_list.append(fx); y_list.append(fy)\n",
    "\n",
    "X_us = np.concatenate(X_list, axis=0)\n",
    "y_us = np.concatenate(y_list, axis=0)\n",
    "X_us = X_us[..., np.newaxis]\n",
    "\n",
    "print(\"UrbanSound8K dataset shape:\", X_us.shape, y_us.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "373891f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> \n",
       "\n",
       " batch_normalization              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> \n",
       "\n",
       " batch_normalization_1            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
       "\n",
       " batch_normalization_2            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> \n",
       "\n",
       " batch_normalization_3            (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                                                   \n",
       "\n",
       " global_average_pooling2d         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)                                               \n",
       "\n",
       " dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
       "\n",
       " dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)               \u001b[38;5;34m160\u001b[0m \n",
       "\n",
       " batch_normalization              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m16\u001b[0m)                \u001b[38;5;34m64\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)              \u001b[38;5;34m4,640\u001b[0m \n",
       "\n",
       " batch_normalization_1            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)                \u001b[38;5;34m128\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)             \u001b[38;5;34m18,496\u001b[0m \n",
       "\n",
       " batch_normalization_2            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)                \u001b[38;5;34m256\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)                   \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)               (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)             \u001b[38;5;34m73,856\u001b[0m \n",
       "\n",
       " batch_normalization_3            (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)                \u001b[38;5;34m512\u001b[0m \n",
       " (\u001b[38;5;33mBatchNormalization\u001b[0m)                                                   \n",
       "\n",
       " global_average_pooling2d         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       " (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)                                               \n",
       "\n",
       " dense_8 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                      \u001b[38;5;34m8,256\u001b[0m \n",
       "\n",
       " dropout_4 (\u001b[38;5;33mDropout\u001b[0m)              (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense_9 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                          \u001b[38;5;34m65\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">106,433</span> (415.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m106,433\u001b[0m (415.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,953</span> (413.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,953\u001b[0m (413.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 175ms/step - accuracy: 0.9446 - loss: 0.1568 - val_accuracy: 0.9566 - val_loss: 0.1152\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 157ms/step - accuracy: 0.9711 - loss: 0.0887 - val_accuracy: 0.9538 - val_loss: 0.1472\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 170ms/step - accuracy: 0.9804 - loss: 0.0628 - val_accuracy: 0.9678 - val_loss: 0.1022\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 186ms/step - accuracy: 0.9843 - loss: 0.0480 - val_accuracy: 0.9758 - val_loss: 0.0712\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 151ms/step - accuracy: 0.9861 - loss: 0.0410 - val_accuracy: 0.9758 - val_loss: 0.0697\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9877 - loss: 0.0354 - val_accuracy: 0.9844 - val_loss: 0.0461\n",
      "Epoch 7/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 147ms/step - accuracy: 0.9908 - loss: 0.0284 - val_accuracy: 0.9099 - val_loss: 0.8270\n",
      "Epoch 8/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.9929 - loss: 0.0215 - val_accuracy: 0.9251 - val_loss: 0.6120\n",
      "Epoch 9/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 150ms/step - accuracy: 0.9928 - loss: 0.0212 - val_accuracy: 0.9896 - val_loss: 0.0351\n",
      "Epoch 10/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.9933 - loss: 0.0185 - val_accuracy: 0.9600 - val_loss: 0.1068\n",
      "Epoch 11/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 153ms/step - accuracy: 0.9948 - loss: 0.0151 - val_accuracy: 0.9520 - val_loss: 0.1380\n",
      "Epoch 12/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 149ms/step - accuracy: 0.9948 - loss: 0.0132 - val_accuracy: 0.9882 - val_loss: 0.0405\n",
      "Epoch 13/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 147ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9812 - val_loss: 0.0599\n",
      "Epoch 14/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9965 - loss: 0.0104 - val_accuracy: 0.9878 - val_loss: 0.0422\n",
      "Epoch 15/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 146ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 0.9862 - val_loss: 0.0484\n",
      "Epoch 16/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 147ms/step - accuracy: 0.9953 - loss: 0.0151 - val_accuracy: 0.9934 - val_loss: 0.0233\n",
      "Epoch 17/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 146ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9568 - val_loss: 0.1275\n",
      "Epoch 18/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 147ms/step - accuracy: 0.9965 - loss: 0.0102 - val_accuracy: 0.9852 - val_loss: 0.0453\n",
      "Epoch 19/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9980 - loss: 0.0069 - val_accuracy: 0.9588 - val_loss: 0.2237\n",
      "Epoch 20/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.9333 - val_loss: 0.4744\n",
      "Epoch 21/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 146ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.9950 - val_loss: 0.0206\n",
      "Epoch 22/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9978 - loss: 0.0078 - val_accuracy: 0.9918 - val_loss: 0.0246\n",
      "Epoch 23/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 149ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9954 - val_loss: 0.0196\n",
      "Epoch 24/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 152ms/step - accuracy: 0.9953 - loss: 0.0126 - val_accuracy: 0.9948 - val_loss: 0.0167\n",
      "Epoch 25/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.9858 - val_loss: 0.0488\n",
      "Epoch 26/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 139ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9944 - val_loss: 0.0203\n",
      "Epoch 27/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 140ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9902 - val_loss: 0.0560\n",
      "Epoch 28/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 142ms/step - accuracy: 0.9977 - loss: 0.0086 - val_accuracy: 0.9946 - val_loss: 0.0221\n",
      "Epoch 29/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.9944 - val_loss: 0.0276\n",
      "Epoch 30/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9976 - loss: 0.0077 - val_accuracy: 0.9940 - val_loss: 0.0208\n",
      "Epoch 31/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 142ms/step - accuracy: 0.9977 - loss: 0.0067 - val_accuracy: 0.9964 - val_loss: 0.0129\n",
      "Epoch 32/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 140ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.9900 - val_loss: 0.0357\n",
      "Epoch 33/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 140ms/step - accuracy: 0.9989 - loss: 0.0033 - val_accuracy: 0.9848 - val_loss: 0.0703\n",
      "Epoch 34/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 145ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9716 - val_loss: 0.1602\n",
      "Epoch 35/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9930 - val_loss: 0.0275\n",
      "Epoch 36/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 140ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9904 - val_loss: 0.0503\n",
      "Epoch 37/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9985 - loss: 0.0037 - val_accuracy: 0.9918 - val_loss: 0.0385\n",
      "Epoch 38/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 142ms/step - accuracy: 0.9984 - loss: 0.0053 - val_accuracy: 0.9954 - val_loss: 0.0183\n",
      "Epoch 39/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9930 - val_loss: 0.0237\n",
      "Epoch 40/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 144ms/step - accuracy: 0.9985 - loss: 0.0047 - val_accuracy: 0.9932 - val_loss: 0.0365\n",
      "Epoch 41/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 140ms/step - accuracy: 0.9977 - loss: 0.0076 - val_accuracy: 0.9924 - val_loss: 0.0244\n",
      "Epoch 42/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 142ms/step - accuracy: 0.9990 - loss: 0.0026 - val_accuracy: 0.9836 - val_loss: 0.0688\n",
      "Epoch 43/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 143ms/step - accuracy: 0.9983 - loss: 0.0056 - val_accuracy: 0.9956 - val_loss: 0.0126\n",
      "Epoch 44/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 140ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.9958 - val_loss: 0.0210\n",
      "Epoch 45/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9964 - val_loss: 0.0164\n",
      "Epoch 46/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.9946 - val_loss: 0.0284\n",
      "Epoch 47/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 141ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9822 - val_loss: 0.0771\n",
      "Epoch 48/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 140ms/step - accuracy: 0.9986 - loss: 0.0043 - val_accuracy: 0.9896 - val_loss: 0.0507\n",
      "Epoch 49/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 145ms/step - accuracy: 0.9992 - loss: 0.0021 - val_accuracy: 0.9934 - val_loss: 0.0260\n",
      "Epoch 50/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 148ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9806 - val_loss: 0.0835\n",
      "\u001b[1m196/196\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 35ms/step - accuracy: 0.9838 - loss: 0.0747\n",
      "UrbanSound8K Test accuracy: 0.9838244915008545\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# # Train/test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_us, y_us, stratify=y_us, test_size=0.2, random_state=42\n",
    "# )\n",
    "\n",
    "# input_shape = X_us.shape[1:]\n",
    "\n",
    "# model_us = models.Sequential([\n",
    "#     layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "#     layers.MaxPooling2D((2,2)),\n",
    "#     layers.Conv2D(32, (3,3), activation='relu'),\n",
    "#     layers.MaxPooling2D((2,2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dropout(0.5),\n",
    "#     layers.Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# model_us.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model_us.summary()\n",
    "\n",
    "# # Train\n",
    "# history_us = model_us.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Evaluate\n",
    "# test_loss, test_acc = model_us.evaluate(X_test, y_test)\n",
    "# print(\"UrbanSound8K Test accuracy:\", test_acc)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_us, y_us, stratify=y_us, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "input_shape = X_us.shape[1:]\n",
    "\n",
    "model_us = models.Sequential([\n",
    "    layers.Conv2D(16, (3,3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_us.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_us.summary()\n",
    "\n",
    "# Train\n",
    "history_us = model_us.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model_us.evaluate(X_test, y_test)\n",
    "print(\"UrbanSound8K Test accuracy:\", test_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e176560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Siren       0.99      0.99      0.99      1960\n",
      "       Siren       0.52      0.60      0.56        40\n",
      "\n",
      "    accuracy                           0.98      2000\n",
      "   macro avg       0.76      0.79      0.77      2000\n",
      "weighted avg       0.98      0.98      0.98      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model_us.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "im = ax.imshow(cm, cmap=\"Blues\")\n",
    "\n",
    "# Show numbers\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "ax.set_xticks(np.arange(2))\n",
    "ax.set_yticks(np.arange(2))\n",
    "ax.set_xticklabels([\"Non-Siren\",\"Siren\"])\n",
    "ax.set_yticklabels([\"Non-Siren\",\"Siren\"])\n",
    "ax.set_xlabel(\"Predicted\")\n",
    "ax.set_ylabel(\"True\")\n",
    "ax.set_title(\"UrbanSound8K Siren Detection Confusion Matrix\")\n",
    "plt.colorbar(im)\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Non-Siren\",\"Siren\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bc810a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd, librosa\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- Config ---\n",
    "SR = 22050\n",
    "WIN_SEC = 1.5\n",
    "HOP_SEC = 0.75\n",
    "WIN = int(SR * WIN_SEC)\n",
    "HOP = int(SR * HOP_SEC)\n",
    "N_MELS = 64\n",
    "\n",
    "def extract_logmel(x, sr=SR, n_mels=N_MELS):\n",
    "    S = librosa.feature.melspectrogram(y=x, sr=sr, n_fft=1024, hop_length=256, n_mels=n_mels)\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    return log_S.astype(np.float32)\n",
    "\n",
    "def file_to_logmel(path, label):\n",
    "    x, sr = librosa.load(path, sr=SR, mono=True)\n",
    "    if np.max(np.abs(x)) > 0: x = x / np.max(np.abs(x))\n",
    "    feats, labels = [], []\n",
    "    if len(x) < WIN: x = np.pad(x, (0, WIN - len(x)))\n",
    "    for start in range(0, max(len(x) - WIN + 1, 1), HOP):\n",
    "        seg = x[start:start+WIN]\n",
    "        feats.append(extract_logmel(seg))\n",
    "        labels.append(label)\n",
    "    return np.stack(feats), np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "045fd6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prate\\AppData\\Local\\Temp\\ipykernel_23476\\2932157490.py:20: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  x, sr = librosa.load(path, sr=SR, mono=True)\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLibsndfileError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\librosa\\core\\audio.py:176\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     y, sr_native = \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m sf.SoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    179\u001b[39m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\librosa\\core\\audio.py:209\u001b[39m, in \u001b[36m__soundfile_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     context = \u001b[43msf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\soundfile.py:690\u001b[39m, in \u001b[36mSoundFile.__init__\u001b[39m\u001b[34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd, compression_level, bitrate_mode)\u001b[39m\n\u001b[32m    688\u001b[39m \u001b[38;5;28mself\u001b[39m._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[32m    689\u001b[39m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m \u001b[38;5;28mself\u001b[39m._file = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode).issuperset(\u001b[33m'\u001b[39m\u001b[33mr+\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.seekable():\n\u001b[32m    692\u001b[39m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\soundfile.py:1265\u001b[39m, in \u001b[36mSoundFile._open\u001b[39m\u001b[34m(self, file, mode_int, closefd)\u001b[39m\n\u001b[32m   1264\u001b[39m     err = _snd.sf_error(file_ptr)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix=\u001b[33m\"\u001b[39m\u001b[33mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.name))\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode_int == _snd.SFM_WRITE:\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[31mLibsndfileError\u001b[39m: Error opening 'datasets/Siren Sound Dataset\\\\ambulance\\\\sound_1.wav': Format not recognised.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNoBackendError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Example: load sireNNet\u001b[39;00m\n\u001b[32m     19\u001b[39m X_sirenNet, y_sirenNet = load_siren_dataset(\u001b[33m\"\u001b[39m\u001b[33mdatasets/sireNNet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m X_sirenSound, y_sirenSound = \u001b[43mload_siren_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatasets/Siren Sound Dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: add UrbanSound8K and ESC loaders similarly (using metadata CSV for labels)\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# --- Merge all ---\u001b[39;00m\n\u001b[32m     25\u001b[39m X_all = np.concatenate([X_sirenNet, X_sirenSound], axis=\u001b[32m0\u001b[39m)[..., np.newaxis]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mload_siren_dataset\u001b[39m\u001b[34m(base_dir)\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os.listdir(folder):\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m\"\u001b[39m\u001b[33m.wav\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m             fx, fy = \u001b[43mfile_to_logmel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# siren = 1\u001b[39;00m\n\u001b[32m      9\u001b[39m             X_list.append(fx); y_list.append(fy)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# traffic as non-siren\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mfile_to_logmel\u001b[39m\u001b[34m(path, label)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfile_to_logmel\u001b[39m(path, label):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     x, sr = \u001b[43mlibrosa\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.max(np.abs(x)) > \u001b[32m0\u001b[39m: x = x / np.max(np.abs(x))\n\u001b[32m     22\u001b[39m     feats, labels = [], []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\librosa\\core\\audio.py:184\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib.PurePath)):\n\u001b[32m    181\u001b[39m     warnings.warn(\n\u001b[32m    182\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[33m\"\u001b[39m, stacklevel=\u001b[32m2\u001b[39m\n\u001b[32m    183\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     y, sr_native = \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\decorator.py:235\u001b[39m, in \u001b[36mdecorate.<locals>.fun\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[32m    234\u001b[39m     args, kw = fix(args, kw, sig)\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\librosa\\util\\decorators.py:63\u001b[39m, in \u001b[36mdeprecated.<locals>.__wrapper\u001b[39m\u001b[34m(func, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m warnings.warn(\n\u001b[32m     56\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m     stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\librosa\\core\\audio.py:240\u001b[39m, in \u001b[36m__audioread_load\u001b[39m\u001b[34m(path, offset, duration, dtype)\u001b[39m\n\u001b[32m    237\u001b[39m     reader = path\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     reader = \u001b[43maudioread\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[32m    243\u001b[39m     sr_native = input_file.samplerate\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python\\Lib\\site-packages\\audioread\\__init__.py:131\u001b[39m, in \u001b[36maudio_open\u001b[39m\u001b[34m(path, backends)\u001b[39m\n\u001b[32m    128\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# All backends failed!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m NoBackendError()\n",
      "\u001b[31mNoBackendError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Dataset loaders ---\n",
    "def load_siren_dataset(base_dir):\n",
    "    X_list, y_list = [], []\n",
    "    for cls in [\"ambulance\",\"firetruck\",\"police\"]:\n",
    "        folder = os.path.join(base_dir, cls)\n",
    "        for f in os.listdir(folder):\n",
    "            if f.endswith(\".wav\"):\n",
    "                fx, fy = file_to_logmel(os.path.join(folder,f), 1) # siren = 1\n",
    "                X_list.append(fx); y_list.append(fy)\n",
    "    # traffic as non-siren\n",
    "    folder = os.path.join(base_dir, \"traffic\")\n",
    "    for f in os.listdir(folder):\n",
    "        if f.endswith(\".wav\"):\n",
    "            fx, fy = file_to_logmel(os.path.join(folder,f), 0)\n",
    "            X_list.append(fx); y_list.append(fy)\n",
    "    return np.concatenate(X_list), np.concatenate(y_list)\n",
    "\n",
    "# Example: load sireNNet\n",
    "X_sirenNet, y_sirenNet = load_siren_dataset(\"datasets/sireNNet\")\n",
    "X_sirenSound, y_sirenSound = load_siren_dataset(\"datasets/Siren Sound Dataset\")\n",
    "\n",
    "# TODO: add UrbanSound8K and ESC loaders similarly (using metadata CSV for labels)\n",
    "\n",
    "# --- Merge all ---\n",
    "X_all = np.concatenate([X_sirenNet, X_sirenSound], axis=0)[..., np.newaxis]\n",
    "y_all = np.concatenate([y_sirenNet, y_sirenSound], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "94900a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess\n",
    "\n",
    "def convert_dataset(base_dir):\n",
    "    for root, _, files in os.walk(base_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".wav\"):\n",
    "                src = os.path.join(root, f)\n",
    "                dst = src.replace(\".wav\", \"_fixed.wav\")\n",
    "                subprocess.run([\n",
    "                    \"ffmpeg\", \"-y\", \"-i\", src,\n",
    "                    \"-ar\", \"22050\", \"-ac\", \"1\", \"-c:a\", \"pcm_s16le\", dst\n",
    "                ])\n",
    "\n",
    "convert_dataset(r\"C:\\Users\\prate\\Downloads\\College Academics\\Minor Project\\Minor Project\\datasets\\Siren Sound Dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, y_all, stratify=y_all, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Optimized CNN ---\n",
    "input_shape = X_all.shape[1:]\n",
    "model_siren = models.Sequential([\n",
    "    layers.Conv2D(16, (3,3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_siren.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_siren.summary()\n",
    "\n",
    "# --- Train ---\n",
    "history = model_siren.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# --- Evaluate ---\n",
    "test_loss, test_acc = model_siren.evaluate(X_test, y_test)\n",
    "print(\"Unified Siren Model Test accuracy:\", test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
